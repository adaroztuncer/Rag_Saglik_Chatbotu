# -*- coding: utf-8 -*-
import os
import pandas as pd
import gradio as gr
import google.generativeai as genai
from huggingface_hub import login
from datasets import load_dataset
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.embeddings.base import Embeddings
from sentence_transformers import SentenceTransformer
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# Ortam deÄŸiÅŸkenlerinden API anahtarlarÄ±nÄ± al
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
HF_TOKEN = os.getenv("HF_TOKEN")

# Google Generative AI yapÄ±landÄ±rmasÄ±
genai.configure(api_key=GEMINI_API_KEY)

# Hugging Face'e giriÅŸ yap
try:
    login(token=HF_TOKEN)
    print("âœ… Hugging Face login baÅŸarÄ±lÄ±.")
except Exception as e:
    print(f"âŒ GiriÅŸ baÅŸarÄ±sÄ±z: {e}")

# Veri setini yÃ¼kle (sadece acibadem parÃ§asÄ±nÄ±)
print("ğŸ“¦ Sadece 'acibadem' veri seti yÃ¼kleniyor...")
data_split = load_dataset(
    "umutertugrul/turkish-hospital-medical-articles",
    split='acibadem'
)

# Veri setinin sÃ¼tunlarÄ±nÄ± kontrol et
print("Veri seti sÃ¼tunlarÄ±:", data_split.column_names)

# DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
print("Veri DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
df = data_split.to_pandas()

# VarsayÄ±lan olarak 'title' ve 'text' sÃ¼tunlarÄ±nÄ± kullan
available_columns = [col for col in ['title', 'text'] if col in df.columns]
if not available_columns:
    raise ValueError("Gerekli sÃ¼tunlar ('title' veya 'text') veri setinde bulunamadÄ±!")

# Content sÃ¼tununu oluÅŸtur
df['content'] = df.apply(
    lambda row: f"{row['title'] if 'title' in row else ''}\n\n{row['text'] if 'text' in row else ''}",
    axis=1
)

print(f"âœ… Toplam kayÄ±t (sadece acibadem): {len(df)}")

# Metinleri parÃ§alara ayÄ±r
print("ğŸ”¹ Metinler parÃ§alara ayrÄ±lÄ±yor...")
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=2000,
    chunk_overlap=50,
    separators=["\n\n", "\n", ".", " "]
)
chunks = []
for text in df['content'].tolist():
    chunks.extend(text_splitter.split_text(text))
print(f"âœ… Toplam chunk sayÄ±sÄ±: {len(chunks)}")

# SentenceTransformer Embeddings sÄ±nÄ±fÄ±
class SentenceTransformerEmbeddings(Embeddings):
    def __init__(self, model_name):
        self.model = SentenceTransformer(model_name)
    def embed_documents(self, texts):
        return self.model.encode(texts, convert_to_tensor=False).tolist()
    def embed_query(self, text):
        return self.model.encode([text], convert_to_tensor=False)[0].tolist()

# Embedding modeli
embedding_model = SentenceTransformerEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Chroma vektÃ¶r veritabanÄ±nÄ± oluÅŸtur veya yÃ¼kle
persist_directory = "./chroma_index"
collection_name = "turhish_hospital_articles"

if os.path.exists(persist_directory):
    print("âœ… Mevcut Chroma vektÃ¶r veritabanÄ± yÃ¼kleniyor...")
    db = Chroma(
        persist_directory=persist_directory,
        embedding_function=embedding_model,
        collection_name=collection_name
    )
else:
    print("ğŸ”¹ Yeni Chroma vektÃ¶r veritabanÄ± oluÅŸturuluyor...")
    db = Chroma.from_texts(
        texts=chunks,
        embedding=embedding_model,
        persist_directory=persist_directory,
        collection_name=collection_name
    )
    print("âœ… Chroma vektÃ¶r veritabanÄ± oluÅŸturuldu ve kaydedildi.")
print(f"ğŸ“¦ Toplam vektÃ¶r sayÄ±sÄ±: {db._collection.count()}")

# LLM (Gemini Flash)
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.6,
    max_tokens=600,
    google_api_key=GEMINI_API_KEY
)

# Chroma retriever
retriever = db.as_retriever(search_kwargs={"k": 3})

# Prompt ÅŸablonu
system_prompt = (
    "Sen bir saÄŸlÄ±k asistanÄ±sÄ±n. KullanÄ±cÄ±dan gelen sorularÄ±, "
    "Chroma veritabanÄ±ndan getirilen ilgili metin parÃ§alarÄ±na dayanarak yanÄ±tla. "
    "EÄŸer soruyu yanÄ±tlamak iÃ§in yeterli bilgi yoksa, 'Bu konu hakkÄ±nda yeterli bilgiye sahip deÄŸilim.' de. Daha fazla bilgi iste.\n\n"
    "{context}"
)

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("human", "{input}")
    ]
)

# RAG zinciri
chain = create_retrieval_chain(
    retriever=retriever,
    combine_docs_chain=create_stuff_documents_chain(llm=llm, prompt=prompt)
)

# Gradio fonksiyonu
def answer_question(user_input, history):
    try:
        # Ã–nceki konuÅŸmalarÄ± birleÅŸtirip modele baÄŸlam olarak gÃ¶nder
        context = "\n".join([f"KullanÄ±cÄ±: {q}\nAsistan: {a}" for q, a in history])
        full_input = f"{context}\nKullanÄ±cÄ±: {user_input}\nAsistan:"
        
        # Modeli Ã§aÄŸÄ±r (Ã¶rnek olarak chain.invoke)
        response = chain.invoke({"input": full_input})["answer"]

        # Yeni mesajÄ± geÃ§miÅŸe ekle
        history = history + [[user_input, response]]
        return "", history  # giriÅŸ kutusunu temizle
    except Exception as e:
        return "", history + [[user_input, f"Bir hata oluÅŸtu: {e}"]]

# Gradio arayÃ¼zÃ¼
with gr.Blocks(theme="soft") as demo:
    gr.Markdown("## ğŸ¥ SaÄŸlÄ±k AsistanÄ± Chatbot")
    gr.Markdown(
        "SaÄŸlÄ±kla ilgili sorularÄ±nÄ±zÄ± yanÄ±tlayan chatbot. "
        "HastalÄ±k belirtileri, tedaviler ve daha fazlasÄ± hakkÄ±nda bilgi alabilirsiniz."
    )

    chatbot = gr.Chatbot(label="ğŸ’¬ Sohbet AlanÄ±")
    user_input = gr.Textbox(
        lines=2,
        placeholder="Sorunuzu buraya yazÄ±n ve Enterâ€™a basÄ±n...",
        label="Soru",
    )
    submit_btn = gr.Button("GÃ¶nder")

    # Butonla gÃ¶nderme
    submit_btn.click(
        fn=answer_question,
        inputs=[user_input, chatbot],
        outputs=[user_input, chatbot]
    )

    # Enter ile gÃ¶nderme
    user_input.submit(
        fn=answer_question,
        inputs=[user_input, chatbot],
        outputs=[user_input, chatbot]
    )

# UygulamayÄ± baÅŸlat
if __name__ == "__main__":
    demo.launch()


