{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA0ZARt-a_uS"
      },
      "source": [
        "# **RAG Tabanlı Sağlık Asistanı Chatbotu** 🏥\n",
        "\n",
        "Bu notebook, Türkçe sağlık makalelerinden oluşan bir veri setini kullanarak bir Retrieval-Augmented Generation (RAG) tabanlı chatbot oluşturur. Chatbot, kullanıcıların sağlıkla ilgili sorularını yanıtlamak için Google Generative AI modellerini ve Chroma vektör veritabanını kullanır. Kullanıcı arayüzü Gradio ile sağlanır.\n",
        "\n",
        "## Colab Ortamına Hazırlık 🔨\n",
        "Bu bölümde, gerekli kütüphaneleri yükleyeceğiz ve ortamı hazırlayacağız."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0dNE4j3a_uW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a2a5c5-3b07-4800-bf5b-78564fd83d6d"
      },
      "source": [
        "# 🧩 Gerekli kütüphaneleri yükle\n",
        "!pip install -q \\\n",
        "    google-generativeai \\\n",
        "    huggingface_hub \\\n",
        "    datasets \\\n",
        "    pandas \\\n",
        "    gradio \\\n",
        "    sentence-transformers \\\n",
        "    langchain \\\n",
        "    langchain-core \\\n",
        "    langchain-chroma \\\n",
        "    langchain_google_genai \\\n",
        "    langchain_text_splitters\n",
        "\n",
        "# Gerekli tüm modülleri import et\n",
        "import os\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Hugging Face ve Veri Seti\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset, Features, Value\n",
        "\n",
        "# Colab\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "\n",
        "# LangChain Metin İşleme\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# LangChain Vektör Deposu ve Gömme (Embeddings)\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# LangChain LLM ve RAG Zinciri\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "print(\"✅ Tüm kütüphaneler başarıyla yüklendi ve import edildi.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tüm kütüphaneler başarıyla yüklendi ve import edildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYDALo1ba_ua"
      },
      "source": [
        "## Ortam Değişkenlerini Yükleme ve API Yapılandırması\n",
        "\n",
        "Bu bölümde, Google Generative AI ve Hugging Face API anahtarlarını yükleyeceğiz. Colab'de `.env` dosyası yerine, API anahtarlarını Colab'in 'Secrets' kısmına ekleyebilirsiniz (Sol panel > Secrets). Güvenlik için bu yöntemi kullanmanız önerilir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSzqSQtYa_uc",
        "outputId": "acdfa4ff-3e30-4c12-9790-68e3acdc7642"
      },
      "source": [
        "# Colab Secrets'tan API anahtarlarını al\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Google Generative AI yapılandırması\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Hugging Face'e giriş yap\n",
        "try:\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"✅ Hugging Face login başarılı.\")\n",
        "except Exception as e:  # Genel hata yakalama\n",
        "    print(f\"❌ Giriş başarısız: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hugging Face login başarılı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuuKGZOpa_ud"
      },
      "source": [
        "## Veri Setini Yükleme ve DataFrame Hazırlığı\n",
        "\n",
        "Bu bölümde, Hugging Face üzerindeki `umutertugrul/turkish-hospital-medical-articles` veri setini yükleyeceğiz, DataFrame'e çevireceğiz ve metinleri birleştirerek `content` sütunu oluşturacağız."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3dqKFmVa_ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773fab1b-0120-4fd1-da48-971b7bd435a8"
      },
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "print(\"📦 Sadece 'acibadem' veri seti yükleniyor...\")\n",
        "\n",
        "# Veri setini yükle (sadece acibadem parçasını)\n",
        "data_split = load_dataset(\n",
        "    \"umutertugrul/turkish-hospital-medical-articles\",\n",
        "    split='acibadem'\n",
        ")\n",
        "\n",
        "# Veri setinin sütunlarını kontrol et\n",
        "print(\"Veri seti sütunları:\", data_split.column_names)\n",
        "\n",
        "# DataFrame'e dönüştür\n",
        "print(\"Veri DataFrame'e dönüştürülüyor...\")\n",
        "df = data_split.to_pandas()\n",
        "\n",
        "# Varsayılan olarak 'title' ve 'text' sütunlarını kullan, 'headings' yoksa hata vermesin\n",
        "available_columns = [col for col in ['title', 'text'] if col in df.columns]\n",
        "if not available_columns:\n",
        "    raise ValueError(\"Gerekli sütunlar ('title' veya 'text') veri setinde bulunamadı!\")\n",
        "\n",
        "# Content sütununu oluştur\n",
        "df['content'] = df.apply(\n",
        "    lambda row: f\"{row['title'] if 'title' in row else ''}\\n\\n{row['text'] if 'text' in row else ''}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(f\"✅ Toplam kayıt (sadece acibadem): {len(df)}\")\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Sadece 'acibadem' veri seti yükleniyor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 09eec7ab-3424-4acd-a20b-2da4af9dfef5)')' thrown while requesting HEAD https://huggingface.co/datasets/umutertugrul/turkish-hospital-medical-articles/resolve/main/README.md\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 09eec7ab-3424-4acd-a20b-2da4af9dfef5)')' thrown while requesting HEAD https://huggingface.co/datasets/umutertugrul/turkish-hospital-medical-articles/resolve/main/README.md\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veri seti sütunları: ['url', 'title', 'text', 'publish_date', 'update_date', 'scrape_date']\n",
            "Veri DataFrame'e dönüştürülüyor...\n",
            "✅ Toplam kayıt (sadece acibadem): 6339\n",
            "                                                 url  \\\n",
            "0  https://www.acibadem.com.tr/ilgi-alani/baso-ba...   \n",
            "1  https://www.acibadem.com.tr/ilgi-alani/endosko...   \n",
            "2  https://www.acibadem.com.tr/ilgi-alani/ablasyo...   \n",
            "3  https://www.acibadem.com.tr/ilgi-alani/hemoglo...   \n",
            "4  https://www.acibadem.com.tr/ilgi-alani/adenit-...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Baso (Bazofil) Nedir? Baso Yüksekliği ve Düşük...   \n",
            "1  Endoskopik Sleeve Gastroplasti Nedir? Nasıl Uy...   \n",
            "2   Ablasyon Nedir? Ablasyon Tedavisi Nasıl Yapılır?   \n",
            "3  🩸 Hemoglobin (HGB) Nedir? Hemoglobin Yüksekliğ...   \n",
            "4  Adenit Nedir? Adenit Belirtileri, Nedenleri ve...   \n",
            "\n",
            "                                                text             publish_date  \\\n",
            "0  Bazofil(Baso), bağışıklık sisteminin alerjik t...  25 Aralık 2024 Çarşamba   \n",
            "1  Endoskopik gastroplastive gastrik sleeve, obez...     24 Haziran 2025 Salı   \n",
            "2  Ablasyon, kalpte yaşanan aritmi (ritim bozuklu...      12 Mayıs 2024 Pazar   \n",
            "3  Hemoglobin(HGB), kırmızı kan hücrelerinde bulu...        13 Ekim 2020 Salı   \n",
            "4  Adenit enfeksiyonlardan kaynaklanan lenf bezle...   17 Nisan 2025 Perşembe   \n",
            "\n",
            "                update_date scrape_date  \\\n",
            "0  25 Haziran 2025 Çarşamba  2025-07-04   \n",
            "1  25 Haziran 2025 Çarşamba  2025-07-04   \n",
            "2     7 Mayıs 2025 Çarşamba  2025-07-04   \n",
            "3    3 Temmuz 2025 Perşembe  2025-07-04   \n",
            "4    17 Nisan 2025 Perşembe  2025-07-04   \n",
            "\n",
            "                                             content  \n",
            "0  Baso (Bazofil) Nedir? Baso Yüksekliği ve Düşük...  \n",
            "1  Endoskopik Sleeve Gastroplasti Nedir? Nasıl Uy...  \n",
            "2  Ablasyon Nedir? Ablasyon Tedavisi Nasıl Yapılı...  \n",
            "3  🩸 Hemoglobin (HGB) Nedir? Hemoglobin Yüksekliğ...  \n",
            "4  Adenit Nedir? Adenit Belirtileri, Nedenleri ve...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1DUs5aa_ug"
      },
      "source": [
        "## Metin Parçalama (Chunking)\n",
        "\n",
        "Bu bölümde, metinleri daha küçük parçalara (chunk) ayıracağız. Bu işlem, vektör veritabanında daha verimli arama yapılmasını sağlar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzZVQXmFa_uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1d134c-7f81-46f2-8ff6-1c02e1dbcaa0"
      },
      "source": [
        "print(\"🔹 Metinler parçalara ayrılıyor...\")\n",
        "\n",
        "# Text splitter ayarları\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,      # Her parça yaklaşık 1000 karakter\n",
        "    chunk_overlap=50,    # Parçalar arasında 100 karakter örtüşme\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
        ")\n",
        "\n",
        "# Content kolonunu kullanarak tüm metinleri chunk'lara ayır\n",
        "chunks = []\n",
        "for text in df['content'].tolist():\n",
        "    chunks.extend(text_splitter.split_text(text))\n",
        "\n",
        "print(f\"✅ Toplam chunk sayısı: {len(chunks)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Metinler parçalara ayrılıyor...\n",
            "✅ Toplam chunk sayısı: 38544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWGyUZd9a_uk"
      },
      "source": [
        "## Vektör Veritabanı Oluşturma\n",
        "\n",
        "Bu bölümde, metin parçalarını Google Generative AI embeddings ile vektörleştireceğiz ve Chroma vektör veritabanında saklayacağız."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCy5Nvlwa_ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b54696-9f5f-4d14-c42b-8c5bd832d47c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Drive'ı bağladığınızdan emin olun\n",
        "\n",
        "# ... (SentenceTransformerEmbeddings sınıfınız burada) ...\n",
        "class SentenceTransformerEmbeddings(Embeddings):\n",
        "    def __init__(self, model_name):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "    def embed_documents(self, texts):\n",
        "        return self.model.encode(texts, convert_to_tensor=False).tolist()\n",
        "    def embed_query(self, text):\n",
        "        return self.model.encode([text], convert_to_tensor=False)[0].tolist()\n",
        "\n",
        "embedding_model = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "# --- KALICI KAYIT İÇİN DÜZELTME ---\n",
        "persist_directory = \"/content/drive/MyDrive/chroma_index_local\"\n",
        "collection_name = \"turkish_hospital_articles\"\n",
        "\n",
        "# Mevcut veritabanını KONTROL ET (Artık Google Drive'da)\n",
        "if os.path.exists(persist_directory):\n",
        "    # Mevcut veritabanını YÜKLE\n",
        "    print(\"✅ Mevcut Chroma vektör veritabanı GOOGLE DRIVE'DAN yüklendi.\")\n",
        "    db = Chroma(\n",
        "        persist_directory=persist_directory,\n",
        "        embedding_function=embedding_model,\n",
        "        collection_name=collection_name\n",
        "    )\n",
        "    print(f\"📦 Toplam vektör sayısı: {db._collection.count()}\")\n",
        "else:\n",
        "    # Yeni veritabanı OLUŞTUR (Sadece ilk çalıştırmada)\n",
        "    print(\"🔹 Veritabanı bulunamadı. GOOGLE DRIVE'A yeni veritabanı oluşturuluyor...\")\n",
        "    print(\"🔹 (Bu işlem chunk sayısına göre zaman alabilir)\")\n",
        "\n",
        "    # 'chunks' değişkeninin bu kod bloğundan ÖNCE tanımlandığından emin olun.\n",
        "    db = Chroma.from_texts(\n",
        "        texts=chunks,  # Parçalara ayrılmış metinler\n",
        "        embedding=embedding_model,\n",
        "        persist_directory=persist_directory,\n",
        "        collection_name=collection_name\n",
        "    )\n",
        "    print(\"✅ Chroma vektör veritabanı oluşturuldu ve GOOGLE DRIVE'A kaydedildi.\")\n",
        "    print(f\"📦 Toplam vektör sayısı: {db._collection.count()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 32478f9c-a217-4b0b-b7c8-bde6804e17c6)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./sentence_bert_config.json\n",
            "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 32478f9c-a217-4b0b-b7c8-bde6804e17c6)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./sentence_bert_config.json\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Veritabanı bulunamadı. GOOGLE DRIVE'A yeni veritabanı oluşturuluyor...\n",
            "🔹 (Bu işlem chunk sayısına göre zaman alabilir)\n",
            "✅ Chroma vektör veritabanı oluşturuldu ve GOOGLE DRIVE'A kaydedildi.\n",
            "📦 Toplam vektör sayısı: 38544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ToGYJ3a_um"
      },
      "source": [
        "## RAG Pipeline Kurulumu\n",
        "\n",
        "Bu bölümde, Retrieval-Augmented Generation (RAG) zincirini oluşturacağız. Bu zincir, kullanıcı sorularını yanıtlamak için Chroma veritabanından ilgili metinleri çeker ve Gemini Flash modelini kullanır."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wrwVjFoa_un"
      },
      "source": [
        "# LLM (Gemini Flash)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.6,\n",
        "    max_tokens=600,\n",
        "    google_api_key=GEMINI_API_KEY\n",
        ")\n",
        "\n",
        "# Chroma retriever\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# Prompt şablonu (Türkçe, sağlık odaklı)\n",
        "system_prompt = (\n",
        "    \"Sen bir sağlık asistanısın. Kullanıcıdan gelen soruları, \"\n",
        "    \"Chroma veritabanından getirilen ilgili metin parçalarına dayanarak yanıtla. \"\n",
        "    \"Eğer soruyu yanıtlamak için yeterli bilgi yoksa, 'Bu konu hakkında yeterli bilgiye sahip değilim.' de. Daha fazla bilgi iste.\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# RAG chain\n",
        "chain = create_retrieval_chain(\n",
        "    retriever=retriever,\n",
        "    combine_docs_chain=create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
        ")\n",
        "\n",
        "#Gradio fonksiyonu\n",
        "def answer_question(user_input, history):\n",
        "    try:\n",
        "        # Önceki konuşmaları birleştirip modele bağlam olarak gönder\n",
        "        context = \"\\n\".join([f\"Kullanıcı: {q}\\nAsistan: {a}\" for q, a in history])\n",
        "        full_input = f\"{context}\\nKullanıcı: {user_input}\\nAsistan:\"\n",
        "\n",
        "        # Modeli çağır (örnek olarak chain.invoke)\n",
        "        response = chain.invoke({\"input\": full_input})[\"answer\"]\n",
        "\n",
        "        # Yeni mesajı geçmişe ekle\n",
        "        history = history + [[user_input, response]]\n",
        "        return \"\", history  # giriş kutusunu temizle\n",
        "    except Exception as e:\n",
        "        return \"\", history + [[user_input, f\"Bir hata oluştu: {e}\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am15UMpSa_uo"
      },
      "source": [
        "## Gradio Arayüzü\n",
        "\n",
        "Bu bölümde, kullanıcı dostu bir web arayüzü oluşturmak için Gradio'yu kullanacağız. Colab'de çalışması için `share=True` ile başlatacağız."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17oyxBnaa_up",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "e21c74fa-591d-45ba-fc27-3aebbede8941"
      },
      "source": [
        "# Gradio arayüzü\n",
        "with gr.Blocks(theme=\"soft\") as demo:\n",
        "    gr.Markdown(\"## 🏥 Sağlık Asistanı Chatbot\")\n",
        "    gr.Markdown(\n",
        "        \"Sağlıkla ilgili sorularınızı yanıtlayan chatbot. \"\n",
        "        \"Hastalık belirtileri, tedaviler ve daha fazlası hakkında bilgi alabilirsiniz.\"\n",
        "    )\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"💬 Sohbet Alanı\")\n",
        "    user_input = gr.Textbox(\n",
        "        lines=2,\n",
        "        placeholder=\"Sorunuzu buraya yazın ve Enter’a basın...\",\n",
        "        label=\"Soru\",\n",
        "    )\n",
        "    submit_btn = gr.Button(\"Gönder\")\n",
        "\n",
        "    # Butonla gönderme\n",
        "    submit_btn.click(\n",
        "        fn=answer_question,\n",
        "        inputs=[user_input, chatbot],\n",
        "        outputs=[user_input, chatbot]\n",
        "    )\n",
        "\n",
        "    # Enter ile gönderme\n",
        "    user_input.submit(\n",
        "        fn=answer_question,\n",
        "        inputs=[user_input, chatbot],\n",
        "        outputs=[user_input, chatbot]\n",
        "    )\n",
        "\n",
        "# Uygulamayı başlat\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3375178813.py:9: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Chatbot Yanıtları\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5f8e7bc67ff2919e1a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f8e7bc67ff2919e1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}